[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "",
    "text": "Abstract. This research project aims to measure the effects of monetary policy shocks on stock price volatility using the Bayesian Structural Vector Autoregressive Model in the Australian economy from 1990 to 2023.\nKeywords. Bayesian Structural VARs, Monetary policy shocks, Stock price volatility, Impulse response"
  },
  {
    "objectID": "index.html#diagnostic-tests",
    "href": "index.html#diagnostic-tests",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "2.1 Diagnostic Tests",
    "text": "2.1 Diagnostic Tests\n\n2.1.1 Autocorrelation/Partial autocorrelation Function Plots\nThe autocorrelation test is used to identify the presence of serial correlation between a variable’s current value and its lagged value, indicating that past values influence the current value.\nThe autocorrelation function (ACF) plots in Figure 3 shows that all the variables except for stock price volatility have non-zero autocorrelation for at least 20 lags, implying that only stock price volatility is a stationary series and the other variables are highly persistent.\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Plots of autocorrelation functions\n\n\nThe partial autocorrelation function (PACF) plots in Figure 4 shows that the partial autocorrelation for all the variables are significant at the first lag. The partial autocorrelation for exchange rates is also significant at 2.\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Plots of partial autocorrelation functions\n\n\n\n\n2.1.2 Unit Root Test\n\nAugmented Dickey-Fuller Test\nThe augmented Dickey-Fuller test of the null hypothesis of unit root nonstationarity was performed to test the presence of the unit root.\nTable 3 shows that the null hypothesis was not rejected at the 1% significance level for all the variables but not for stock price volatility, implying that all the variables except for stock price volatility are nonstationary series. However, stock price volatility is the log of bipower variation and took logarithmic scale twice,\n\n\n\n\n\nVariable\nTest statistic\nCritical value\nStationarity\n\n\n\n\nGDP\n-1.296\n-3.99\nNo\n\n\nInterest rates\n-2.991\n-3.46\nNo\n\n\nConsumer price index\n-2.845\n-3.99\nNo\n\n\nExchange rates\n-2.181\n-3.46\nNo\n\n\nStock prices\n-3.186\n-3.99\nNo\n\n\nStock price volatility\n-4.543\n-3.46\nYes\n\n\n\n\n\n\n\nTable 3: Augmented Dickey-Fuller test results\n\n\nTable 4 shows that the Augmented Dickey-Fuller test results on the first difference of the variables. We find that all the variables are unit root stationary at the 1% significance level, and conclude that all the variables are integrated of order one, \\(I(1)\\).\n\n\n\n\n\nVariable\nTest statistic\nCritical value\nStationarity\n\n\n\n\nGDP\n-5.258\n-3.46\nYes\n\n\nInterest rates\n-5.574\n-2.58\nYes\n\n\nConsumer price index\n-6.089\n-3.46\nYes\n\n\nExchange rates\n-7.589\n-2.58\nYes\n\n\nStock prices\n-6.905\n-3.46\nYes\n\n\nStock price volatility\n-8.322\n-2.58\nYes\n\n\n\n\n\n\n\nTable 4: Augmented Dickey-Fuller test results on the first difference"
  },
  {
    "objectID": "index.html#model-specification",
    "href": "index.html#model-specification",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "3.1 Model Specification",
    "text": "3.1 Model Specification\nThis study uses a Bayesian Structural vector autoregression (BSVAR) model to measure the dynamic and contemporaneous relationships between variables. The endogenous variables in the model are the following: \\[\nY_t=\n\\begin{pmatrix}\n   gdp_t\n\\\\ICR_t\n\\\\cpi_t\n\\\\EXR_t\n\\\\stp_t\n\\\\vol_t\n\\end{pmatrix}\n\\] \\(Y_t\\) contains six variables ordered as\n   (1) Real GDP, \\(gdp_t\\),\n   (2) Interest rates, \\(ICR_t\\),\n   (3) Consumer price index, \\(cpi_t\\),\n   (4) Exchange rates from AUD to USD, \\(EXR_t\\),\n   (5) Stock prices, \\(stp_t\\), and\n   (6) Stock price volatility, \\(vol_t\\).\n\nStructural Form\nThe Structural VAR model can be represented as follows: \\[\n\\begin{gather}\nB_0Y_t = b_0 + \\sum_{i=1}^{p} B_iY_{t-i} + u_t \\\\\nu_t|Y_{t-1} \\sim iid(0_N, I_N)\n\\end{gather}\n\\] where\n   \\(Y_t\\) is an \\(N \\times 1\\) vector of endogenous variables at time \\(t\\),\n   \\(B_0\\) is an \\(N \\times N\\) matrix capturing contemporaneous relationships between variables,\n   \\(u_t\\) is an \\(N \\times 1\\) vector conditionally on \\(Y_{t-1}\\) orthogonal structural shocks,\n   \\(N\\) is the number of endogeneous variables, and \\(p\\) is the lag length.\n\n\nReduced Form\nThrough the transformation, the corresponding Structural VAR model can be represented as the reduced form VAR model as follows: \\[\n\\begin{gather}\nY_t = \\mu_0 + \\sum_{i=1}^{p} A_iY_{t-i} + \\epsilon_t \\\\\n\\epsilon_t|Y_{t-1} \\sim iid(0_N, \\Sigma)\n\\end{gather}\n\\] where\n   \\(Y_t\\) is an \\(N \\times 1\\) vector of endogenous variables at time \\(t\\),\n   \\(A_i\\) is an \\(N \\times N\\) matrix of autoregressive slope parameters,\n   \\(\\mu_0\\) is an \\(N \\times 1\\) vector of constant terms,\n   \\(\\epsilon_t\\) is an \\(N \\times 1\\) vector of the white noise error terms,\n   \\(\\Sigma\\) is an \\(N \\times N\\) covariance matrix of error terms \\(\\epsilon_t\\), where \\(\\Sigma = B_0^{-1} {B_0^{-1}}'\\),\n   \\(N\\) is the number of endogeneous variables, and \\(p\\) is the lag length."
  },
  {
    "objectID": "index.html#bayes-theorem",
    "href": "index.html#bayes-theorem",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "3.2 Bayes’ theorem",
    "text": "3.2 Bayes’ theorem\nFor parameter estimation, the Bayes’ theorem is used to derive the joint posterior distribution.\nThe joint posterior distribution of \\(A\\) and \\(\\Sigma\\) can be estimated as follows: \\[\n\\begin{align}\n\\underbrace{p(A,\\Sigma|Y,X)}_{\\text{Posterior}} &\\propto L(A,\\Sigma|Y,X) \\cdot p(A,\\Sigma)\n\\\\ &\\propto \\underbrace{L(A,\\Sigma|Y,X)}_{\\text{Likelihood function}} \\cdot \\underbrace{p(A|\\Sigma) \\cdot p(\\Sigma)}_{\\text{Prior}}\n\\end{align}\n\\]"
  },
  {
    "objectID": "index.html#standard-bayesian-svar-model",
    "href": "index.html#standard-bayesian-svar-model",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "4.1 Standard Bayesian SVAR Model",
    "text": "4.1 Standard Bayesian SVAR Model\n\n4.1.1 Model Specification\nThe reduced form can be represented in a matrix form as follows: \\[\n\\begin{gather}\nY = XA + E \\\\\n\\\\ E|X \\sim MN_{T \\times N}(0_{T \\times N},\\Sigma_{N \\times N},I_T) \\\\\n\\end{gather}\n\\] $$$$\n\\[\n\\begin{aligned}\nY = \\begin{bmatrix} y_{1}' \\\\y_{2}'  \\\\. \\\\. \\\\. \\\\y_{T}' \\end{bmatrix}_{T \\times N} \\quad\nA = \\begin{bmatrix}\\mu_{0}' \\\\A_{1}' \\\\.\\\\.\\\\.\\\\A_{p}' \\end{bmatrix}_{K \\times N} \\quad\nx_t =\\begin{bmatrix}\\ 1 \\\\y_{t-1} \\\\.\\\\.\\\\.\\\\y_{t-p} \\end{bmatrix}_{K \\times 1} \\quad\nX = \\begin{bmatrix}\\ x_{1}' \\\\x_{2}' \\\\.\\\\.\\\\.\\\\x_{T}' \\end{bmatrix}_{T \\times K} \\quad\nE = \\begin{bmatrix}\\ \\epsilon _{1}'  \\\\\\epsilon _{2}' \\\\.\\\\.\\\\.\\\\\\epsilon _{T}' \\end{bmatrix}_{T \\times N}\n\\end{aligned}\n\\]\nwhere\n   \\(Y\\) is a \\(T \\times N\\) matrix of endogenous variables at time \\(T\\),\n   \\(A\\) is a \\(K \\times N\\) matrix of autoregressive slope parameters,\n   \\(X\\) is a \\(T \\times N\\) matrix of covariates,\n   \\(E\\) is a \\(T \\times N\\) matrix of the white noise error terms,\n   \\(\\Sigma\\) is an \\(N \\times N\\) row-specific covariance matrix of error terms\n   \\(I_T\\) is an \\(T \\times T\\) identity matrix representing the column-specific covariance matrix of error, and\n   \\(N\\) is the number of endogeneous variables,\n   \\(T\\) is the number of time periods,\n   \\(p\\) is the lag length, and\n   \\(K = 1 + pN\\).\n\n\n4.1.2 Estimation Procedure\nFor estimation, the Bayes’ theorem is used to derive the joint posterior distribution for \\(A\\) and \\(\\Sigma\\). \\[\n\\begin{align}\n\\underbrace{p(A,\\Sigma|Y,X)}_{\\text{Posterior}} &\\propto L(A,\\Sigma|Y,X) \\cdot p(A,\\Sigma)\n\\\\ &\\propto \\underbrace{L(A,\\Sigma|Y,X)}_{\\text{Likelihood function}} \\cdot \\underbrace{p(A|\\Sigma) \\cdot p(\\Sigma)}_{\\text{Prior}}\n\\end{align}\n\\] This implies the following form for the kernel of the likelihood function: \\[\n\\begin{align}\nL(A,\\Sigma|Y,X) &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(Y-XA)'(Y-XA) \\right] \\right\\}\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}}\n\\\\ &\\times \\exp \\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1}(A-\\hat{A})'X'X(A-\\hat{A}) \\right] \\right\\}\n\\\\ &\\times \\exp \\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1}(Y-X \\hat{A})'(Y-X \\hat{A}) \\right] \\right\\}\n\\end{align}\n\\] where \\[\n\\begin{align}\n\\hat{A} &= (X'X)^{-1}X'Y\n\\\\ \\hat{\\Sigma} &= \\frac{1}{T} (Y-X \\hat{A})'(Y-X \\hat{A})\n\\end{align}\n\\] are from the maximum likelihood estimation.\nThe natural-conjugate prior distribution where \\(A\\) is matrix normal and \\(\\Sigma\\) follows inverse Wishart distribution has the same form as the joint posterior distribution for \\(A\\) and \\(\\Sigma\\). \\[\n\\begin{gather}\np(A,\\Sigma) = p(A|\\Sigma) \\cdot p(\\Sigma) \\\\\n\\\\ A|\\Sigma \\sim MN_{K \\times N}(\\underline{A},\\Sigma,\\underline{V}) \\\\\n\\\\ \\Sigma \\sim IW_N(\\underline{S},\\underline{\\nu})\n\\end{gather}\n\\] This implies the following form for the kernel of the natural-conjugate prior distribution: \\[\n\\begin{align}\np(A,\\Sigma) &= p(A|\\Sigma) \\cdot p(\\Sigma) \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{N+K+\\underline{v}+1}{2}}\n\\\\ &\\times \\exp \\left\\{-\\frac{1}{2}tr \\left[\\Sigma^{-1}(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A}) \\right] \\right\\}\n\\\\ &\\times \\exp \\left\\{-\\frac{1}{2}tr \\left[\\Sigma^{-1}\\underline{S} \\right] \\right\\}\n\\end{align}\n\\]\nThe posterior distribution is given by the product of the likelihood and the priors. \\[\n\\begin{align}\np(A,\\Sigma|Y,X) &\\propto L(A,\\Sigma|Y,X) \\cdot p(A,\\Sigma) \\\\\n\\\\ &\\propto L(A,\\Sigma|Y,X) \\cdot p(A|\\Sigma) \\cdot p(\\Sigma) \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2} tr \\left[ \\Sigma^{-1}(A-\\hat{A})'X'X(A-\\hat{A}) \\right] \\right\\} \\cdot \\exp \\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1}(Y-X \\hat{A})'(Y-X \\hat{A}) \\right] \\right\\}\n\\\\ &\\times \\det(\\Sigma)^{-\\frac{N+K+\\underline{v}+1}{2}} \\cdot \\exp\\left\\{-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A})] \\right\\} \\cdot \\exp\\left\\{-\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}] \\right\\} \\\\\n\\\\ &\\propto \\det{(\\Sigma)}^{-\\frac{T+N+K+\\underline{\\nu}+1}{2}}\n\\\\ &\\times \\exp \\left\\{-\\frac{1}{2} tr \\left[\\Sigma^{-1} \\left[(A-\\hat{A})'X'X(A-\\hat{A})+(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A})+(Y-X\\hat{A})'(Y-X\\hat{A})+\\underline{S} \\right] \\right] \\right\\} \\\\\n\\\\ &\\propto \\det{(\\Sigma)}^{-\\frac{T+N+K+\\underline{\\nu}+1}{2}}\n\\\\ &\\times \\exp \\left\\{ -\\frac{1}{2} tr \\left[\\Sigma^{-1}\\left[(A-\\overline{A})'\\overline{V}^{-1} (A-\\overline{A})+\\underline{S}+Y'Y+\\underline{A}'\\underline{V}^{-1}\\underline{A}-\\overline{A}'\\overline{V}^{-1} \\overline{A} \\right] \\right] \\right\\}\n\\end{align}\n\\]\nCombining the terms and completing the squares for the terms within the square brackets yields the following the joint posterior distributions for \\(A\\) and \\(\\Sigma\\): \\[\n\\begin{gather}\np(A,\\Sigma|Y,X) = p(A|Y,X,\\Sigma) \\cdot p(\\Sigma|Y,X) = MNIW_{K \\times N}(\\overline{A}, \\overline{V}, \\overline{S}, \\overline{\\nu})\n\\\\\n\\\\ p(A|Y,X,\\Sigma) = MN_{K \\times N}(\\overline{A}, \\Sigma, \\overline{V}) \\\\\n\\\\ p(\\Sigma|Y,X) = IW_N(\\overline{S},\\overline{\\nu}) \\\\\n\\end{gather}\n\\]\nwhere the parameter of the joint posterior distribution are the following: \\[\n\\begin{align}\n\\overline{V} &= (X'X + \\underline{V}^{-1})^{-1}\n\\\\ \\overline{A} &= \\overline{V}(X'Y + \\underline{V}^{-1}\\underline{A})\n\\\\ \\overline{\\nu} &= T + \\underline{\\nu}\n\\\\ \\overline{S} &= \\underline{S} + Y'Y + \\underline{A}'\\underline{V}^{-1}\\underline{A} - \\overline{A}'\\overline{V}^{-1}\\overline{A}\n\\end{align}\n\\]\nUsing Minnesota prior, we set the prior mean of \\(\\underline{A}\\) and \\(\\underline{V}\\) as the following:\n\\[\n\\begin{align}\n\\underline{A} = \\begin{bmatrix} \\mathbf{0}_{N \\times 1} \\\\ I_N \\\\ \\mathbf{0}_{N \\times (p-1)N} \\end{bmatrix}\n\\end{align}\n\\]\n\\[\n\\begin{align}\n\\underline{A} &= \\left[ \\mathbf{0}_{N \\times 1} \\quad I_N \\quad \\mathbf{0}_{N \\times (p-1)N} \\right]'\n\\\\ Var[vec(A)] &= \\Sigma \\otimes  \\underline{V}\n\\\\ \\underline{V} &= \\text{diag}([\\kappa_2 \\quad \\kappa_1 (\\mathbf{p}^{-2} \\otimes \\imath'_N)])\n\\\\ \\mathbf{p} &= [1,2, ..., p], \\qquad \\imath_N = [1,...,1]\n\\end{align}\n\\]\n   \\(\\kappa_1\\) is overall shrinkage level of autoregressive slopes, where common value is \\(0.02^2\\)\n   \\(\\kappa_2\\) is overall shrinkage of the constant term\n\n\n4.1.3 Algorithm Validation\nTo check the validity of the algorithms, two independent bi-variate Gaussian random walk processes with 1,000 observations were generated to simulate unit-root non-stationary macroeconomic variables.\n\n\n\n\n\n\n\n\n\n\n\nSee R code\nRW.baseline &lt;- function(data, p, sign.restrictions, S) {\n  \n  # Create Y and X matries\n  ############################################################\n  Y           &lt;- data[(p+1):nrow(data),]\n  X           &lt;- matrix(1, nrow(Y), 1)\n  for (i in 1:p){\n    X         &lt;- cbind(X,data[(p+1):nrow(data)-i,])\n    }\n\n  N           &lt;- ncol(Y)    # number of variables\n  K           &lt;- 1+p*N\n  # p                       # number of lags\n  # S                       # number of posterior draws\n  \n  # Convert it into matrix form\n  Y = as.matrix(Y)\n  X = as.matrix(X)\n  \n  # Calculate the MLE\n  ############################################################\n  A.hat       &lt;- solve(t(X)%*%X)%*%t(X)%*%Y                \n  Sigma.hat   &lt;- t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)  \n  \n  # Specify the prior distribution parameters\n  ############################################################\n  kappa.1     &lt;- 0.02^2\n  kappa.2     &lt;- 100\n  \n  A.prior     &lt;- matrix(0, nrow(A.hat), ncol(A.hat))\n  A.prior[2:(N+1),] &lt;- diag(N)\n  V.prior     &lt;- diag(c(kappa.2, kappa.1*((1:p)^(-2))%x%rep(1,N)))\n  S.prior     &lt;- diag(diag(Sigma.hat))\n  nu.prior    &lt;- N+1\n  \n  # Specify the matrix normal-inverse Wishart posterior parameters\n  ############################################################\n  V.bar.inv   &lt;- t(X)%*%X + diag(1/diag(V.prior))\n  V.bar       &lt;- solve(V.bar.inv)\n  A.bar       &lt;- V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)\n  nu.bar      &lt;- nrow(Y) + nu.prior\n  S.bar       &lt;- S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar\n  S.bar.inv   &lt;- solve(S.bar)\n  \n  # Draw Posterior distribution\n  ############################################################\n  ## Draw from the Reduced Form\n  ### Draw Sigma from the inverse Wishart distribution\n  Sigma.posterior   &lt;- rWishart(S, df=nu.bar, Sigma=S.bar.inv)\n  Sigma.posterior   &lt;- apply(Sigma.posterior,3,solve)            \n  Sigma.posterior   &lt;- array(Sigma.posterior,c(N,N,S))\n  \n  ### Draw A from matrix-variate normal distribution\n  A.posterior       &lt;- array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S)) \n  \n  # Initialise arrays to store posterior draws\n  B0.posterior      &lt;- array(NA, c(N,N,S))\n  B1.posterior      &lt;- array(NA, c(N,K,S))\n  \n  for (s in 1:S){\n    ## Draw from the Structural Form\n    ### Draw B0\n    cholSigma.s        &lt;- chol(Sigma.posterior[,,s])\n    L                  &lt;- t(chol(V.bar))\n    B0.posterior[,,s]  &lt;- solve(t(cholSigma.s)) \n    A.posterior[,,s]   &lt;- A.bar + L%*%A.posterior[,,s]%*%cholSigma.s\n    \n    ### Draw Bplus\n    B1.posterior[,,s]  &lt;- B0.posterior[,,s]%*%t(A.posterior[,,s])\n    }\n  \n  # Identification via sign restrictions\n  ############################################################\n  # Generate corresponding R matrix\n  R &lt;- diag(sign.restrictions)\n  \n  # Initialise arrays for store Q identified estimates\n  i.vec &lt;- c()\n  Q.iden      &lt;- array(NA, c(N,N,S))\n  B0.iden     &lt;- array(NA, c(N,N,S))\n  B1.iden     &lt;- array(NA, c(N,K,S))\n  \n  for (s in 1:S){\n    B0.tilde      &lt;- B0.posterior[,,s]\n    B1.tilde      &lt;- B1.posterior[,,s]\n    \n    sign.restrictions.do.not.hold = TRUE\n    i=1\n    while (sign.restrictions.do.not.hold){\n      X           &lt;- matrix(rnorm(N*N), N, N)         \n      QR          &lt;- qr(X, tol=1e-10)\n      Q           &lt;- qr.Q(QR, complete=TRUE)\n      R           &lt;- qr.R(QR, complete=TRUE)\n      Q           &lt;- t(Q%*%diag(sign(diag(R))))\n      B0          &lt;- Q%*%B0.tilde                    \n      B1          &lt;- Q%*%B1.tilde                   \n      B0.inv      &lt;- solve(B0)      \n      check       &lt;- all(c(B0[1,1], B0[2,2]) &gt; 0)\n      \n      if (check){sign.restrictions.do.not.hold=FALSE}\n      i=i+1\n      }\n    \n    i.vec &lt;- c(i.vec, i) \n    Q.iden[,,s]   &lt;- Q\n    B0.iden[,,s]  &lt;- B0\n    B0.mean       &lt;- apply(B0.iden, 1:2, mean)\n    B1.iden[,,s]  &lt;- B1\n    B1.mean       &lt;- apply(B1.iden, 1:2, mean)\n    }\n  \n  return(list(B0.mean = B0.mean, B1.mean = B1.mean, \n              A.posterior = A.posterior, Sigma.posterior = Sigma.posterior))\n  }\n\n\nThe results show that\n\n\n\nMean of the Matrix B[0]\n\n\n0.6395591\n-0.0220170\n\n\n0.0402778\n0.6467075\n\n\n\n\n\n\n\n\nMean of the Matrix B[+]\n\n\n0.0346082\n0.6354305\n-0.0212149\n\n\n0.0155527\n0.0446449\n0.6432964\n\n\n\n\n\n\n\n\nMean of the A posterior\n\n\n0.0537239\n0.0189261\n\n\n0.9939985\n0.0071675\n\n\n0.0008838\n0.9946591\n\n\n\n\n\n\n\n\nMean of the Sigma posterior\n\n\n0.9635555\n-0.0116637\n\n\n-0.0116637\n0.9415589"
  },
  {
    "objectID": "index.html#bayesian-svar-model-with-t-distributed-innovations",
    "href": "index.html#bayesian-svar-model-with-t-distributed-innovations",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "4.2 Bayesian SVAR Model with t-distributed Innovations",
    "text": "4.2 Bayesian SVAR Model with t-distributed Innovations\n\n4.2.1 Model Specification\nStock price volatility\n\\[\n\\begin{align}\nE_T &\\sim t_N(0, \\Sigma, \\nu)\n\\end{align}\n\\] Then, the reduced form can be represented in a matrix form as follows: \\[\n\\begin{gather}\nY = XA + E \\\\\n\\\\ E|X, \\lambda \\sim MN_{T \\times N}(0_{T \\times N},\\Sigma_{N \\times N},\\lambda I_T)\n\\end{gather}\n\\] where lambda is inverse gamma 2 distributed with shape and ..\n\\[\n\\lambda \\sim IG2(s_{\\lambda}, \\nu_{\\lambda})\n\\]\n\n\n4.2.2 Estimation Procedure\nUsing the Bayes’ theorem, the joint posterior distribution for \\(A\\) and \\(\\Sigma\\) is the following: \\[\n\\begin{align}\n\\underbrace{p(A,\\Sigma|Y,X)}_{\\text{Posterior}} &\\propto L(A,\\Sigma|Y,X) \\cdot p(A,\\Sigma)\n\\\\ &\\propto \\underbrace{L(A,\\Sigma|Y,X)}_{\\text{Likelihood function}} \\cdot \\underbrace{p(A|\\Sigma) \\cdot p(\\Sigma)}_{\\text{Prior}}\n\\end{align}\n\\]\nThe kernel of the likelihood function follows as: \\[\n\\begin{align}\nL(A,\\Sigma|Y,X,\\lambda) &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(\\lambda I_T)^{-\\frac{N}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2} \\text{tr} \\left[\\Sigma^{-1}(Y-XA)'(\\lambda I_T)^{-1}(Y-XA) \\right] \\right\\}\n\\end{align}\n\\] The conditional posterior distribution of \\(A\\) and \\(\\Sigma\\): \\[\n\\begin{align}\np(A,\\Sigma|Y,X,\\lambda) &\\propto L(A,\\Sigma|Y,X,\\lambda) \\cdot p(A,\\Sigma) \\\\\n\\\\ &\\propto L(A,\\Sigma|Y,X,\\lambda) \\cdot p(A|\\Sigma,\\lambda) \\cdot p(\\Sigma|\\lambda) \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(\\lambda I_T)^{-\\frac{N}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2} tr[\\Sigma^{-1} (Y-XA)' (\\lambda I_T)^{-1} (Y-XA) ] \\right\\}\n\\\\ &\\times\n\\det(\\Sigma)^{-\\frac{N+k+\\underline{\\nu}+1}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A})'\\underline{V}^{-1}(A-\\underline{A})] \\right\\} \\cdot \\exp \\left\\{ -\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}] \\right\\} \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T+N+K+\\underline{\\nu}+1}{2}} \\cdot \\det(\\lambda I_T)^{-\\frac{N}{2}}\n\\\\ &\\times \\exp \\left\\{-\\frac{1}{2} tr[\\Sigma^{-1}(Y'(\\lambda I_T)^{-1}Y - 2A'X'(\\lambda I_T)^{-1}Y + A'X'(\\lambda I_T)^{-1}XA + A'\\underline{V}^{-1}A -2A'\\underline{V}^{-1}\\underline{A} + \\underline{A}'\\underline{V}^{-1}\\underline{A} + \\underline{S})] \\right\\}\n\\end{align}\n\\] This follows: \\[\n\\begin{gather}\np(A,\\Sigma|Y,X,\\lambda) = p(A|Y,X,\\Sigma, \\lambda) \\cdot p(\\Sigma|Y,X,\\lambda) = MNIW_{K \\times N}(\\overline{A}, \\overline{V}, \\overline{S}, \\overline{\\nu}) \\\\\n\\\\ p(A|Y,X,\\Sigma,\\lambda) = MN_{K \\times N}(\\overline{A}, \\Sigma, \\overline{V}) \\\\\n\\\\ p(\\Sigma|Y,X,\\lambda) = IW_N(\\overline{S},\\overline{\\nu}) \\\\\n\\end{gather}\n\\] where \\[\n\\begin{align}\n\\overline{V} &= [X'(\\lambda I_T)^{-1}X + \\underline{V}^{-1}]^{-1} \\\\\n\\overline{A} &= \\overline{V}[X'(\\lambda I_T)^{-1}Y + \\underline{V}^{-1}\\underline{A}] \\\\\n\\overline{S} &= Y'(\\lambda I_T)^{-1}Y + \\underline{A}'\\underline{V}^{-1}\\underline{A} - \\overline{A}'\\overline{V}^{-1}\\overline{A} + \\underline{S} \\\\\n\\overline{\\nu} &= \\underline{\\nu} + T\n\\end{align}\n\\]\nThe conditional posterior distribution of \\(\\lambda\\): \\[\n\\begin{align}\np(\\lambda|Y,X,A,\\Sigma) &\\propto L(A,\\Sigma,\\lambda|Y,X) \\cdot p(A,\\Sigma) \\cdot p(\\lambda) \\\\\n\\\\ &\\propto L(A,\\Sigma,\\lambda|Y,X) \\cdot p(\\lambda) \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(\\lambda I_T)^{-\\frac{N}{2}} \\cdot\n\\exp \\left\\{-\\frac{1}{2} tr[\\Sigma^{-1} (Y-XA)' (\\lambda I_T)^{-1} (Y-XA)] \\right\\}\n\\\\ &\\times \\lambda^{-\\frac{\\underline{\\nu_{\\lambda}}+2}{2}} \\cdot\n\\exp \\left\\{-\\frac{1}{2}\\frac{\\underline{s_{\\lambda}}}{\\lambda} \\right\\} \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(I_T)^{-\\frac{N}{2}} \\cdot\n\\exp \\left\\{-\\frac{1}{2}\\frac{1}{\\lambda} tr[\\Sigma^{-1}(Y-XA)'(Y-XA)] \\right\\} \\\\\n&\\times \\lambda^{-\\frac{TN}{2}} \\cdot \\lambda^{-\\frac{\\underline{\\nu_{\\lambda}}+2}{2}} \\cdot\n\\exp \\left\\{-\\frac{1}{2}\\frac{\\underline{s_{\\lambda}}}{\\lambda} \\right\\} \\\\\n\\\\ &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\cdot \\det(I_T)^{-\\frac{N}{2}} \\cdot \\lambda^{-\\frac{TN+\\underline{\\nu_{\\lambda}}+2}{2}} \\cdot \\exp \\left\\{-\\frac{1}{2}\\frac{1}{\\lambda} [tr(\\Sigma^{-1}(Y-XA)'(Y-XA)) + \\underline{s_{\\lambda}}] \\right\\}\n\\end{align}\n\\] This follows \\[\n\\begin{align}\n\\lambda|Y,X, A,\\Sigma &\\sim IG2(\\overline{s_{\\lambda}},\\overline{\\nu_{\\lambda}})\n\\end{align}\n\\] where \\[\n\\begin{align}\n\\overline{s_{\\lambda}} &= tr[\\Sigma^{-1}(Y-XA)'(Y-XA)] + \\underline{s_{\\lambda}} \\\\\n\\overline{\\nu_{\\lambda}} &= \\underline{\\nu_{\\lambda}} + TN\n\\end{align}\n\\]\n\n\n4.2.3 Algorithm Validation\nTo check the validity of the algorithms, two independent bi-variate Gaussian random walk processes with 1,000 observations were generated to simulate unit-root non-stationary macroeconomic variables.\n\nGibbs Sampler\nInitialise \\(\\lambda\\) at \\(\\lambda^{(0)}\\) From S = 1,\n\nDraw \\(\\Sigma^{(s)} \\sim P(\\Sigma|Y,X,\\lambda^{(s-1)})\\) from the \\(IW_N(\\overline{S},\\overline{\\nu})\\) distribution\nDraw \\(A^{(s)} \\sim P(A|Y,X,\\Sigma^{(s)},\\lambda^{(s-1)})\\) from the \\(MN_{K \\times N}(\\overline{A},\\Sigma^{(s)}, \\overline{V})\\) distribution\nDraw \\(\\lambda^{(s)} \\sim P(\\lambda|Y,X,A^{(s)},\\Sigma^{(s)})\\) from \\(IG2(\\overline{s_{\\lambda}},\\overline{\\nu_{\\lambda}})\\) distribution\n\n\n\nSee R code\nRW.extended &lt;- function(data, p, sign.restrictions, S) {\n  \n  # Create Y and X matries\n  #########################################################\n  Y           &lt;- data[(p+1):nrow(data),]\n  X           &lt;- matrix(1, nrow(Y), 1)\n  for (i in 1:p){\n    X         &lt;- cbind(X,data[(p+1):nrow(data)-i,])\n    }\n  \n  N           &lt;- ncol(Y)    # number of variables\n  K           &lt;- 1+p*N\n  # p                       # number of lags\n  # S                       # number of posterior draws\n  \n  # Convert it into matrix form\n  Y = as.matrix(Y)\n  X = as.matrix(X)\n  \n  # Calculate the MLE\n  ############################################################\n  A.hat       &lt;- solve(t(X)%*%X)%*%t(X)%*%Y                \n  Sigma.hat   &lt;- t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)\n  \n  # Specify prior distribution parameters\n  ############################################################\n  kappa.1     &lt;- 0.02^2\n  kappa.2     &lt;- 100\n  \n  A.prior     &lt;- matrix(0, nrow(A.hat), ncol(A.hat))\n  A.prior[2:(N+1),] &lt;- diag(N)\n  V.prior     &lt;- diag(c(kappa.2, kappa.1*((1:p)^(-2))%x%rep(1,N)))\n  S.prior     &lt;- diag(diag(Sigma.hat))\n  nu.prior    &lt;- N+1\n  s.prior.lambda    &lt;- 5   # assume that it is fixed\n  nu.prior.lambda   &lt;- 5   # assume that it is fixed\n  lambda            &lt;- s.prior.lambda/rchisq(1, nu.prior.lambda)\n  \n  # Initialise arrays to store posterior draws\n  Sigma.posterior   &lt;- array(NA, c(N,N,S))\n  A.posterior       &lt;- array(NA, c(K,N,S))\n  lambda.posterior  &lt;- rep(NA, S)\n  B0.posterior      &lt;- array(NA, c(N,N,S))\n  B1.posterior      &lt;- array(NA, c(N,K,S))\n  \n  for (s in 1:S){\n    \n  # Specify the matrix normal-inverse Wishart posterior parameters\n  ############################################################\n  V.bar.inv  &lt;- t(X)%*%X/lambda + diag(1/diag(V.prior))\n  V.bar      &lt;- solve(V.bar.inv)\n  A.bar      &lt;- V.bar%*%(t(X)%*%Y/lambda + diag(1/diag(V.prior))%*%A.prior)\n  nu.bar     &lt;- nrow(Y) + nu.prior\n  S.bar      &lt;- S.prior + t(Y)%*%Y/lambda + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar\n  S.bar.inv  &lt;- solve(S.bar)\n  \n  # Draw Posterior distribution\n  ############################################################\n  ## Draw from the Reduced Form\n  ### Draw Sigma from the inverse Wishart distribution\n  Sigma.posterior.inv   &lt;- rWishart(1, df=nu.bar, Sigma=S.bar.inv)[,,1]\n  Sigma.posterior[,,s]  &lt;- solve(Sigma.posterior.inv)\n  \n  ### Draw A from matrix-variate normal distribution\n  A.posterior[,,s]      &lt;- matrix(mvtnorm::rmvnorm(1, mean=as.vector(A.bar), sigma=Sigma.posterior[,,s]%x%V.bar), ncol=N)\n  \n  ### Draw lambda from inverse gamma 2 distribution\n  s.posterior.lambda    &lt;- sum(diag(Sigma.posterior.inv%*%t(Y-X%*%A.posterior[,,s])%*%(Y-X%*%A.posterior[,,s]))) + s.prior.lambda\n  nu.posterior.lambda   &lt;- nrow(Y)*2 + nu.prior.lambda\n  lambda   &lt;- s.posterior.lambda / rchisq(1, nu.posterior.lambda)\n  lambda.posterior[s]   &lt;- lambda\n  \n  ## Draw from the Structural Form\n  ### Draw B0\n  cholSigma.s        &lt;- chol(Sigma.posterior[,,s])\n  B0.posterior[,,s]  &lt;- solve(t(cholSigma.s)) \n  \n  ### Draw Bplus\n  B1.posterior[,,s]  &lt;- B0.posterior[,,s]%*%t(A.posterior[,,s])\n  }\n  \n  # Identification via sign restrictions \n  ############################################################\n  # Generate corresponding R matrix\n  R &lt;- diag(sign.restrictions)\n  \n  # Initialise arrays for storage matrices\n  i.vec &lt;- c()\n  Q.iden      &lt;- array(NA, c(N,N,S))\n  B0.iden     &lt;- array(NA, c(N,N,S))\n  B1.iden     &lt;- array(NA, c(N,K,S))\n  \n  for (s in 1:S){\n    B0.tilde      &lt;- B0.posterior[,,s]\n    B1.tilde      &lt;- B1.posterior[,,s]\n    \n    sign.restrictions.do.not.hold = TRUE\n    i=1\n    while (sign.restrictions.do.not.hold){\n      X           &lt;- matrix(rnorm(N*N), N, N)         \n      QR          &lt;- qr(X, tol=1e-10)\n      Q           &lt;- qr.Q(QR, complete=TRUE)\n      R           &lt;- qr.R(QR, complete=TRUE)\n      Q           &lt;- t(Q %*% diag(sign(diag(R))))\n      B0          &lt;- Q%*%B0.tilde                    \n      B1          &lt;- Q%*%B1.tilde                   \n      B0.inv      &lt;- solve(B0)      \n      check       &lt;- all(c(B0[1,1], B0[2,2]) &gt; 0)\n      \n      if (check){sign.restrictions.do.not.hold=FALSE}\n      i=i+1\n      }\n    \n    i.vec &lt;- c(i.vec, i) \n    Q.iden[,,s]   &lt;- Q\n    B0.iden[,,s]  &lt;- B0\n    B0.mean       &lt;- apply(B0.iden, 1:2, mean)\n    B1.iden[,,s]  &lt;- B1\n    B1.mean       &lt;- apply(B1.iden, 1:2, mean)\n    }\n  \n  return(list(B0.mean = B0.mean, B1.mean = B1.mean, \n              A.posterior = A.posterior, Sigma.posterior = Sigma.posterior,\n              lambda.posterior = lambda.posterior))\n  }\n\n\nThe results shows that\n\n\n\nMean of the Matrix B[0]\n\n\n0.8765303\n0.0103838\n\n\n0.0102820\n0.8870493\n\n\n\n\n\n\n\n\nMean of the Matrix B[+]\n\n\n0.0439633\n0.8717085\n0.0110613\n\n\n0.0184024\n0.0161803\n0.8826846\n\n\n\n\n\n\n\n\nMean of the A posterior\n\n\n0.0496270\n0.0178939\n\n\n0.9944672\n0.0068237\n\n\n0.0007951\n0.9950129\n\n\n\n\n\n\n\n\nMean of the Sigma posterior\n\n\n0.5925605\n-0.0067195\n\n\n-0.0067195\n0.5793049\n\n\n\n\n\n\n\n\nMean of the lambda\n\n\nlambda\n\n\n\n\n1.859239"
  },
  {
    "objectID": "index.html#bayesian-svar-model-with-common-stochastic-volatility",
    "href": "index.html#bayesian-svar-model-with-common-stochastic-volatility",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "4.3 Bayesian SVAR Model with Common Stochastic Volatility",
    "text": "4.3 Bayesian SVAR Model with Common Stochastic Volatility\n\n4.3.1 Model Specification\n\n\n4.3.2 Estimation Procedure\n\n\n4.3.3 Algorithm Validation"
  },
  {
    "objectID": "index.html#standard-bayesian-svar-model-1",
    "href": "index.html#standard-bayesian-svar-model-1",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "5.1 Standard Bayesian SVAR model",
    "text": "5.1 Standard Bayesian SVAR model\n\\[\nf(B_0,B_+)=\\Theta_0=B=\n\\begin{bmatrix}\n* & - & * & * & * & * \\\\\n* & + & * & * & * & * \\\\\n* & - & * & * & * & * \\\\\n* & + & * & * & * & * \\\\\n* & * & * & * & * & * \\\\\n* & * & * & * & * & * \\\\\n\\end{bmatrix}\n\\]\n\\[\n\\textbf{R}=\\begin{bmatrix}\n-1 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & -1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n\\end{bmatrix}\n\\]\n1990 Q2 onwards..\n\n\n\nMean of the Matrix B[0]\n\n\n\n\n\n\n\n\n\n\n0.9392373\n0.0771727\n1.5552181\n-0.4447673\n-0.2303591\n-0.0342951\n\n\n-32.9480207\n0.9337222\n-72.6889787\n10.0131052\n0.2911390\n0.0301144\n\n\n3.1276181\n-0.0479449\n0.2121022\n0.8987436\n0.1017737\n0.0042477\n\n\n1.0055520\n0.0217106\n-2.4204602\n-0.4742329\n0.1023033\n0.0186687\n\n\n2.4773759\n-0.0219417\n0.9583310\n0.6956288\n-0.3264287\n0.0121941\n\n\n2.2775883\n0.0290890\n-3.7960174\n-0.2528960\n0.2888981\n-0.0421410\n\n\n\n\n\n\n\n\nMean of the Matrix B[+]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.0181740\n0.9399431\n0.0765264\n1.5549731\n-0.4445939\n-0.2308149\n-0.0334683\n-0.0005417\n-0.0003400\n0.0003518\n-0.0000171\n-0.0002033\n-0.0004886\n-0.0001632\n-0.0001679\n0.0000826\n-0.0002633\n0.0001148\n-0.0000981\n0.0003140\n-0.0003824\n-0.0002425\n-0.0000743\n-0.0000653\n-0.0000914\n\n\n-0.7277146\n-32.9471774\n0.9241449\n-72.6893610\n10.0129699\n0.2920235\n0.0300528\n0.0001635\n-0.0033587\n0.0003658\n-0.0001897\n0.0002399\n-0.0004424\n0.0002435\n-0.0013512\n0.0001154\n-0.0001403\n0.0000346\n-0.0001165\n0.0001469\n-0.0005657\n-0.0000636\n-0.0000848\n0.0002590\n-0.0000167\n\n\n0.0178035\n3.1272778\n-0.0465295\n0.2121893\n0.8996819\n0.1019037\n0.0037746\n0.0002428\n-0.0003136\n-0.0001366\n-0.0000711\n-0.0001822\n0.0001230\n0.0003521\n0.0004686\n0.0000465\n-0.0003975\n-0.0002697\n0.0002147\n-0.0000096\n0.0001825\n-0.0000083\n-0.0001093\n-0.0001062\n0.0000145\n\n\n0.0038559\n1.0052319\n0.0218192\n-2.4210433\n-0.4754387\n0.1024997\n0.0183809\n0.0001504\n0.0000697\n-0.0003860\n0.0003981\n-0.0005449\n0.0000859\n-0.0000449\n-0.0002662\n0.0000060\n0.0002539\n-0.0002055\n-0.0000948\n-0.0000806\n-0.0001105\n0.0001221\n-0.0000516\n0.0000344\n0.0000922\n\n\n0.0185323\n2.4780556\n-0.0211821\n0.9583534\n0.6957753\n-0.3257361\n0.0123818\n-0.0001574\n0.0000328\n-0.0000359\n0.0001261\n-0.0003630\n0.0006849\n0.0001031\n0.0000542\n-0.0000576\n-0.0000417\n-0.0002786\n0.0001761\n0.0000844\n0.0003918\n-0.0001767\n-0.0000145\n-0.0000944\n-0.0001287\n\n\n0.0113551\n2.2762888\n0.0294449\n-3.7962639\n-0.2531228\n0.2892347\n-0.0413747\n-0.0001715\n0.0001725\n-0.0001739\n0.0005446\n-0.0000519\n0.0001816\n0.0001533\n0.0000496\n-0.0000605\n0.0002759\n-0.0005109\n0.0000155\n0.0000326\n-0.0001944\n0.0000124\n-0.0000572\n0.0000728\n-0.0000336\n\n\n\n\n\nImpulse response functions of the baseline model show a positive monetary policy shock on variables. The shaded area represents 68% of the confidence interval. In the short run, GDP decreases gradually, but a year after the shock, GDP decreases at a steeper rate. In the short run, interest rates immediately respond to the shock and normalised after five years of the shock. The consumer price index slightly decreases in the short run. The exchange rate has a positive effect in the short and long run. The stock price has a positive effect in the short run, but it does not have a positive effect in the long run.\n\n\nSee R code\np=4\nS=1000\nh=20\nsign.restrictions = c(-1, 1, -1, 1, 0, 0)\n\n  # Create Y and X matries\n  ############################################################\n  Y           &lt;- variables[(p+1):nrow(variables),]\n  X           &lt;- matrix(1, nrow(Y), 1)\n  for (i in 1:p){\n    X         &lt;- cbind(X,variables[(p+1):nrow(variables)-i,])\n    }\n\n  N           &lt;- ncol(Y)    # number of variables\n  K           &lt;- 1+p*N\n  # p                       # number of lags (data frequency (quarter))\n  # S                       # number of posterior draws\n  # h                       # forecast horizon\n  \n  # Convert it into matrix form\n  Y = as.matrix(Y)\n  X = as.matrix(X)\n  \n  # Calculate the MLE\n  ############################################################\n  A.hat       &lt;- solve(t(X)%*%X)%*%t(X)%*%Y                \n  Sigma.hat   &lt;- t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)  \n  \n  # Specify the prior distribution parameters\n  ############################################################\n  kappa.1     &lt;- 1\n  kappa.2     &lt;- 100\n  \n  A.prior     &lt;- matrix(0, nrow(A.hat), ncol(A.hat))\n  A.prior[2:(N+1),] &lt;- diag(N)\n  V.prior     &lt;- diag(c(kappa.2, kappa.1*((1:p)^(-2))%x%rep(1,N)))\n  S.prior     &lt;- diag(diag(Sigma.hat))\n  nu.prior    &lt;- N+1\n  \n  # Specify the matrix normal-inverse Wishart posterior parameters\n  ############################################################\n  V.bar.inv   &lt;- t(X)%*%X + diag(1/diag(V.prior))\n  V.bar       &lt;- solve(V.bar.inv)\n  A.bar       &lt;- V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)\n  nu.bar      &lt;- nrow(Y) + nu.prior\n  S.bar       &lt;- S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar\n  S.bar.inv   &lt;- solve(S.bar)\n  \n  # Draw Posterior distribution\n  ############################################################\n  ## Draw from the Reduced Form\n  ### Draw Sigma from the inverse Wishart distribution\n  Sigma.posterior   &lt;- rWishart(S, df=nu.bar, Sigma=S.bar.inv)\n  Sigma.posterior   &lt;- apply(Sigma.posterior,3,solve)            \n  Sigma.posterior   &lt;- array(Sigma.posterior,c(N,N,S))\n  \n  ### Draw A from matrix-variate normal distribution\n  A.posterior       &lt;- array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S)) \n  \n  # Initialise arrays to store posterior draws\n  B0.posterior      &lt;- array(NA, c(N,N,S))\n  B1.posterior      &lt;- array(NA, c(N,K,S))\n  \n  for (s in 1:S){\n    ## Draw from the Structural Form\n    ### Draw B0\n    cholSigma.s        &lt;- chol(Sigma.posterior[,,s])\n    L                  &lt;- t(chol(V.bar))\n    B0.posterior[,,s]  &lt;- solve(t(cholSigma.s)) \n    A.posterior[,,s]   &lt;- A.bar + L%*%A.posterior[,,s]%*%cholSigma.s\n    \n    ### Draw Bplus\n    B1.posterior[,,s]  &lt;- B0.posterior[,,s]%*%t(A.posterior[,,s])\n    }\n  \n  # Identification via sign restrictions\n  ############################################################\n  # Generate corresponding R matrix\n  R &lt;- diag(sign.restrictions)\n  \n  # Initialise arrays for store Q identified estimates\n  i.vec &lt;- c()\n  Q.iden      &lt;- array(NA, c(N,N,S))\n  B0.iden     &lt;- array(NA, c(N,N,S))\n  B1.iden     &lt;- array(NA, c(N,K,S))\n#  B0.inverse      &lt;- array(NA, c(N,N,S))\n  \n  for (s in 1:S){\n    B0.tilde      &lt;- B0.posterior[,,s]\n    B1.tilde      &lt;- B1.posterior[,,s]\n    \n    sign.restrictions.do.not.hold = TRUE\n    i=1\n    while (sign.restrictions.do.not.hold){\n      X           &lt;- matrix(rnorm(N*N), N, N)         \n      QR          &lt;- qr(X, tol=1e-10)\n      Q           &lt;- qr.Q(QR, complete=TRUE)\n      R           &lt;- qr.R(QR, complete=TRUE)\n      Q           &lt;- t(Q%*%diag(sign(diag(R))))\n      B0          &lt;- Q%*%B0.tilde                    \n      B1          &lt;- Q%*%B1.tilde                   \n      B0.inv      &lt;- solve(B0)      \n      check       &lt;- all(B0.inv[1,2]&lt;0, B0.inv[2,2]&gt;0, B0.inv[3,2]&lt;0, B0.inv[4,2]&gt;0)\n      \n      if (check){sign.restrictions.do.not.hold=FALSE}\n      i=i+1\n      }\n    \n    i.vec &lt;- c(i.vec, i) \n    Q.iden[,,s]   &lt;- Q\n    B0.iden[,,s]  &lt;- B0\n#    B0.inverse[,,s]   &lt;- B0.inv\n    B1.iden[,,s]  &lt;- B1\n  }\n    B0.mean       &lt;- apply(B0.iden, 1:2, mean)\n    B1.mean       &lt;- apply(B1.iden, 1:2, mean)\n\nh = 20\n  \nB.posterior &lt;- array(NA, c(N,N,S))\n  \n  for (s in 1:S){\n  B.posterior[,,s] &lt;- solve(B0.iden[,,s])\n  }\n  \n  IRF.posterior     = array(NA,c(N,N,h+1,S))\n  IRF.inf.posterior = array(NA,c(N,N,S))\n#  FEVD.posterior    = array(NA,c(N,N,h+1,S))\n  J                 = cbind(diag(N),matrix(0,N,N*(p-1)))\n  \n  for (s in 1:S){\n    # Define A matrix in VAR(1) representation\n    A.bold  = rbind(t(A.posterior[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))\n    IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) %*% B.posterior[,,s]\n    A.bold.power    = A.bold\n    for (i in 1:(h+1)){\n      if (i==1){\n        IRF.posterior[,,i,s]        = B.posterior[,,s]\n      } else {\n        IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% B.posterior[,,s]\n        A.bold.power                = A.bold.power %*% A.bold\n      }\n# for (n in 1:N){\n#        for (nn in 1:N){\n#          FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)\n#        }\n#      }\n#      FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]\n#      FEVD.posterior    = 100*FEVD.posterior\n    }\n  }\n#FEVD.posterior    = 100*FEVD.posterior\n\n# Impulse Response Function plots\n############################################################\nIRF.posterior.mps = IRF.posterior[,2,,]\nIRFs.k1           = apply(IRF.posterior.mps,1:2,median)\nIRFs.inf.k1       = apply(IRF.posterior.mps,1,mean)\nrownames(IRFs.k1) = colnames(variables)\n\nlibrary(HDInterval)\nIRFs.k1.hdi    = apply(IRF.posterior.mps,1:2,hdi, credMass=0.68)\nhh             = 1:(h+1)\n\npar(mfrow=c(3,2), mar=c(3,3,2,2),cex.axis=1.5, cex.lab=1.5)\nfor (n in 1:N){\n  ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,1:(h+1)],0)\n  plot(hh,IRFs.k1[n,hh], type=\"l\", ylim=ylims, axes=FALSE, xlab=\"\", main=rownames(IRFs.k1)[n])\n  if (n==5){\n    axis(1,c(1,5,9,13,17,21),c(\"0\",\"1yr\",\"2yr\",\"3yr\",\"4yr\",\"5yr\"))\n  } else {\n    axis(1,c(1,5,9,13,17,21),c(\"0\",\"1yr\",\"2yr\",\"3yr\",\"4yr\",\"5yr\"))\n  }\n  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))\n  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col=mcxs1.shade1,border=mcxs1.shade1)\n  abline(h=0)\n  lines(hh, IRFs.k1[n,hh],lwd=2,col=\"darkblue\")\n}\n\n\n\n\n\n\n\n\n\nImpulse response functions of the t-distributed innovation model show a positive monetary policy shock on variables. In the short run, interest rates immediately respond to the shock and normalised around five years after the shock. The consumer price index slightly decreases in the short run. There are no significant effects on GDP, stock prices, or stock price volatility. Consumer price index and exchange rates decrease slightly, but they are also not significant."
  },
  {
    "objectID": "index.html#bayesian-svar-model-with-t-distributed-innovations-1",
    "href": "index.html#bayesian-svar-model-with-t-distributed-innovations-1",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "5.2 Bayesian SVAR Model with t-distributed Innovations",
    "text": "5.2 Bayesian SVAR Model with t-distributed Innovations\n\n\n\nMean of the Matrix B[0]\n\n\n\n\n\n\n\n\n\n\n-399.0842969\n0.5074372\n84.187484\n7.032087\n5.4695126\n0.3221044\n\n\n-29.3087200\n11.4184837\n-132.293665\n-6.291390\n-4.1427583\n-0.2045171\n\n\n39.8322090\n1.6342429\n-692.267485\n-1.062727\n0.0159517\n-0.2191469\n\n\n-16.2118482\n0.1793060\n-1.128349\n109.927470\n-8.9458784\n0.6955231\n\n\n-0.0665983\n0.4699924\n24.056405\n5.404019\n-2.4266793\n0.1476714\n\n\n14.1708032\n0.6122880\n-10.731886\n3.549880\n-0.2231298\n-0.0336320\n\n\n\n\n\n\n\n\nMean of the Matrix B[+]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-2.3082090\n-399.082943\n0.5062772\n84.18805\n7.032572\n5.4703844\n0.3217202\n-0.0001843\n-0.0002470\n-0.0008276\n0.0000910\n-0.0000187\n-0.0004908\n-0.0001273\n0.0003276\n-0.0000864\n-0.0001525\n0.0000549\n0.0000036\n0.0001532\n0.0001422\n-0.0001369\n-0.0001544\n-0.0001149\n0.0001903\n\n\n-1.8444374\n-29.308650\n11.4191879\n-132.29349\n-6.291032\n-4.1433031\n-0.2040285\n-0.0000663\n0.0002555\n-0.0003191\n0.0001555\n0.0002267\n-0.0003189\n0.0002972\n-0.0000636\n0.0001962\n-0.0000824\n0.0003324\n-0.0001312\n-0.0001586\n-0.0001845\n0.0000832\n-0.0001262\n0.0000438\n-0.0000143\n\n\n-4.1273361\n39.832169\n1.6350671\n-692.26644\n-1.062386\n0.0148697\n-0.2194642\n0.0000360\n-0.0003308\n-0.0000026\n0.0003498\n0.0000309\n0.0008865\n-0.0000216\n-0.0001052\n0.0001302\n0.0002754\n-0.0000844\n0.0000389\n0.0001432\n-0.0001735\n0.0000810\n0.0000017\n-0.0001345\n-0.0000532\n\n\n-0.4301577\n-16.211110\n0.1777091\n-1.12926\n109.927994\n-8.9465824\n0.6947430\n0.0003177\n0.0000496\n-0.0001436\n-0.0001690\n-0.0003376\n-0.0004350\n-0.0000290\n0.0002638\n-0.0001062\n0.0001045\n0.0000441\n-0.0001442\n0.0001309\n0.0000243\n-0.0000765\n0.0001698\n-0.0000291\n0.0002161\n\n\n0.0762025\n-0.066128\n0.4706931\n24.05757\n5.404298\n-2.4277892\n0.1474967\n-0.0004755\n0.0001249\n0.0003970\n-0.0002709\n-0.0001053\n0.0004251\n-0.0000446\n0.0000342\n-0.0000040\n-0.0001510\n0.0001327\n-0.0005338\n-0.0000681\n-0.0004237\n0.0000940\n0.0000754\n0.0000433\n0.0002321\n\n\n0.1612883\n14.171693\n0.6116311\n-10.73216\n3.550133\n-0.2234287\n-0.0331363\n-0.0001957\n0.0001305\n-0.0002040\n0.0001588\n-0.0003020\n0.0005484\n0.0001785\n0.0000278\n0.0003407\n0.0000711\n-0.0002600\n0.0002638\n-0.0000204\n-0.0000760\n-0.0001309\n-0.0002043\n0.0002730\n0.0000602\n\n\n\n\n\n\n\nSee R code\np = 4\nsign.restrictions = c(-1, 1, -1, 1, 0, 0)\nS = 1000\nh=20\n\n  # Create Y and X matries\n  #########################################################\n  Y           &lt;- variables[(p+1):nrow(variables),]\n  X           &lt;- matrix(1, nrow(Y), 1)\n  for (i in 1:p){\n    X         &lt;- cbind(X,variables[(p+1):nrow(variables)-i,])\n    }\n  \n  N           &lt;- ncol(Y)    # number of variables\n  K           &lt;- 1+p*N\n  # p                       # number of lags\n  # S                       # number of posterior draws\n  h           &lt;- 20         # forecast horizon\n  \n  # Convert it into matrix form\n  Y = as.matrix(Y)\n  X = as.matrix(X)\n  \n  # Calculate the MLE\n  ############################################################\n  A.hat       &lt;- solve(t(X)%*%X)%*%t(X)%*%Y                \n  Sigma.hat   &lt;- t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)\n  \n  # Specify prior distribution parameters\n  ############################################################\n  kappa.1     &lt;- 5\n  kappa.2     &lt;- 100\n  \n  A.prior     &lt;- matrix(0, nrow(A.hat), ncol(A.hat))\n  A.prior[2:(N+1),] &lt;- diag(N)\n  V.prior     &lt;- diag(c(kappa.2, kappa.1*((1:p)^(-2))%x%rep(1,N)))\n  S.prior     &lt;- diag(diag(Sigma.hat))\n  nu.prior    &lt;- N+1\n  s.prior.lambda    &lt;- 5   # assume that it is fixed\n  nu.prior.lambda   &lt;- 5   # assume that it is fixed\n  lambda            &lt;- s.prior.lambda/rchisq(1, nu.prior.lambda)\n  \n  # Initialise arrays to store posterior draws\n  Sigma.posterior   &lt;- array(NA, c(N,N,S))\n  A.posterior       &lt;- array(NA, c(K,N,S))\n  lambda.posterior  &lt;- rep(NA, S)\n  B0.posterior      &lt;- array(NA, c(N,N,S))\n  B1.posterior      &lt;- array(NA, c(N,K,S))\n  \n  for (s in 1:S){\n    \n  # Specify the matrix normal-inverse Wishart posterior parameters\n  ############################################################\n  V.bar.inv  &lt;- t(X)%*%X/lambda + diag(1/diag(V.prior))\n  V.bar      &lt;- solve(V.bar.inv)\n  A.bar      &lt;- V.bar%*%(t(X)%*%Y/lambda + diag(1/diag(V.prior))%*%A.prior)\n  nu.bar     &lt;- nrow(Y) + nu.prior\n  S.bar      &lt;- S.prior + t(Y)%*%Y/lambda + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar\n  S.bar.inv  &lt;- solve(S.bar)\n  \n  # Draw Posterior distribution\n  ############################################################\n  ## Draw from the Reduced Form\n  ### Draw Sigma from the inverse Wishart distribution\n  Sigma.posterior.inv   &lt;- rWishart(1, df=nu.bar, Sigma=S.bar.inv)[,,1]\n  Sigma.posterior[,,s]  &lt;- solve(Sigma.posterior.inv)\n  \n  ### Draw A from matrix-variate normal distribution\n  A.posterior[,,s]      &lt;- matrix(mvtnorm::rmvnorm(1, mean=as.vector(A.bar), sigma=Sigma.posterior[,,s]%x%V.bar), ncol=N)\n  \n  ### Draw lambda from inverse gamma 2 distribution\n  s.posterior.lambda    &lt;- sum(diag(Sigma.posterior.inv%*%t(Y-X%*%A.posterior[,,s])%*%(Y-X%*%A.posterior[,,s]))) + s.prior.lambda\n  nu.posterior.lambda   &lt;- nrow(Y)*2 + nu.prior.lambda\n  lambda   &lt;- s.posterior.lambda / rchisq(1, nu.posterior.lambda)\n  lambda.posterior[s]   &lt;- lambda\n  \n  ## Draw from the Structural Form\n  ### Draw B0\n  cholSigma.s        &lt;- chol(Sigma.posterior[,,s])\n  B0.posterior[,,s]  &lt;- solve(t(cholSigma.s))\n  #B0.inv[,,s] &lt;- solve(B0.posterior[,,s])\n\n  ### Draw Bplus\n  B1.posterior[,,s]  &lt;- B0.posterior[,,s]%*%t(A.posterior[,,s])\n  }\n  \n  # Identification via sign restrictions \n  ############################################################\n  # Generate corresponding R matrix\n  R &lt;- diag(sign.restrictions)\n  \n  # Initialise arrays for storage matrices\n  i.vec &lt;- c()\n  Q.iden      &lt;- array(NA, c(N,N,S))\n  B0.iden     &lt;- array(NA, c(N,N,S))\n  B1.iden     &lt;- array(NA, c(N,K,S))\n  \n  for (s in 1:S){\n    B0.tilde      &lt;- B0.posterior[,,s]\n    B1.tilde      &lt;- B1.posterior[,,s]\n    \n    sign.restrictions.do.not.hold = TRUE\n    i=1\n    while (sign.restrictions.do.not.hold){\n      X           &lt;- matrix(rnorm(N*N), N, N)         \n      QR          &lt;- qr(X, tol=1e-10)\n      Q           &lt;- qr.Q(QR, complete=TRUE)\n      R           &lt;- qr.R(QR, complete=TRUE)\n      Q           &lt;- t(Q %*% diag(sign(diag(R))))\n      B0          &lt;- Q%*%B0.tilde                    \n      B1          &lt;- Q%*%B1.tilde                   \n      B0.inv      &lt;- solve(B0)      \n      check       &lt;- all(B0.inv[1,2]&lt;0, B0.inv[2,2]&gt;0, B0.inv[3,2]&lt;0, B0.inv[4,2]&gt;0)\n      \n      if (check){sign.restrictions.do.not.hold=FALSE}\n      i=i+1\n      }\n    \n    i.vec &lt;- c(i.vec, i) \n    Q.iden[,,s]   &lt;- Q\n    B0.iden[,,s]  &lt;- B0\n    B1.iden[,,s]  &lt;- B1\n    }\n  \n  h = 20\n  \nB.posterior &lt;- array(NA, c(N,N,S))\n  \n  for (s in 1:S){\n  B.posterior[,,s] &lt;- solve(B0.iden[,,s])\n  }\n  \n  IRF.posterior     = array(NA,c(N,N,h+1,S))\n  IRF.inf.posterior = array(NA,c(N,N,S))\n#  FEVD.posterior    = array(NA,c(N,N,h+1,S))\n  J                 = cbind(diag(N),matrix(0,N,N*(p-1)))\n  \n  for (s in 1:S){\n    # Define A matrix in VAR(1) representation\n    A.bold  = rbind(t(A.posterior[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))\n    IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) %*% B.posterior[,,s]\n    A.bold.power    = A.bold\n    for (i in 1:(h+1)){\n      if (i==1){\n        IRF.posterior[,,i,s]        = B.posterior[,,s]\n      } else {\n        IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% B.posterior[,,s]\n        A.bold.power                = A.bold.power %*% A.bold\n      }\n# for (n in 1:N){\n#        for (nn in 1:N){\n#          FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)\n#        }\n#      }\n#      FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]\n#      FEVD.posterior    = 100*FEVD.posterior\n    }\n  }\n  \n#FEVD.posterior    = 100*FEVD.posterior\n\n# Impulse Response Function plots\n############################################################\nIRF.posterior.mps = IRF.posterior[,2,,]\nIRFs.k1           = apply(IRF.posterior.mps,1:2,median)\nIRFs.inf.k1       = apply(IRF.posterior.mps,1,mean)\nrownames(IRFs.k1) = colnames(variables)\n\nlibrary(HDInterval)\nIRFs.k1.hdi    = apply(IRF.posterior.mps,1:2,hdi, credMass=0.68)\nhh             = 1:(h+1)\n\npar(mfrow=c(3,2), mar=c(3,3,2,2),cex.axis=1.5, cex.lab=1.5)\nfor (n in 1:N){\n  ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,1:(h+1)],0)\n  plot(hh,IRFs.k1[n,hh], type=\"l\", ylim=ylims, axes=FALSE, xlab=\"\", main=rownames(IRFs.k1)[n])\n  if (n==5){\n    axis(1,c(1,5,9,13,17,21),c(\"0\",\"1yr\",\"2yr\",\"3yr\",\"4yr\",\"5yr\"))\n  } else {\n    axis(1,c(1,5,9,13,17,21),c(\"0\",\"1yr\",\"2yr\",\"3yr\",\"4yr\",\"5yr\"))\n  }\n  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))\n  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col=mcxs2.shade1,border=mcxs2.shade1)\n  abline(h=0)\n  lines(hh, IRFs.k1[n,hh],lwd=2,col=\"darkblue\")\n}"
  },
  {
    "objectID": "index.html#bayesian-svar-model-with-common-stochastic-volatility-1",
    "href": "index.html#bayesian-svar-model-with-common-stochastic-volatility-1",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "5.3 Bayesian SVAR Model with Common Stochastic Volatility",
    "text": "5.3 Bayesian SVAR Model with Common Stochastic Volatility"
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "The Effects of Monetary Policy Shocks on Stock Price Volatility: Evidence from the Australian Economy",
    "section": "References",
    "text": "References"
  }
]